{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# MatConvNet - An introduction <img src='https://raw.githubusercontent.com/IoannisKansizoglou/DeepLectures/master/images/logoDUTH.png' width='30%' align='right'>\n",
    "\n",
    "**Laboratory of Robotics & Automation**<br />\n",
    "_Kansizoglou Ioannis, PhD Candidate_<br />\n",
    "<i> ikansizo@pme.duth.gr </i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Σκοπός βιβλιοθήκης\n",
    "\n",
    "Περιλαμβάνει ένα σύνολο κλάσεων, δομών και συναρτήσεων για την ανάπτυξη, εκπαίδευση και ελέγχου νευρωνικών δικτύων με την χρήση του matlab2016b, χωρίς την απαραίτητη χρήση κάρτας γραφικών (GPU).\n",
    "\n",
    "Με τη βοήθεια της βιβλιοθήκης κάθε επίπεδο (layer) του δικτύου μπορεί να υλοποιηθεί απλά με τη χρήση της κατάλληλης συνάρτησης.\n",
    "\n",
    "Παρέχεται δωρεάν στο παρακάτω [link](http://www.vlfeat.org/matconvnet/). Εμείς θα χρησιμοποιήσουμε την έκδοση **1.0-beta23**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Χρήσιμα αρχεία\n",
    "\n",
    "Ας περιηγηθούμε στον φάκελο **example**. Εκεί βρίσκονται τέσσερα **.m** αρχεία.\n",
    "1. Το **run_experiment.m** είναι το αρχείο το οποίο εκτελούμε για να ξεκινήσουμε μία εκπαίδευση. Αυτό διαχειρίζεται τα άλλα τρία αρχεία που είναι συναρτήσεις.\n",
    "2. Το **cnn.m** αναλαμβάνει την συλλογή των δεδομένων (training and testing data) και μεταπηδά από την μία διαδικασία στην άλλη.\n",
    "3. Το **cnn_init.m** αρχικοποιεί ορισμένες παραμέτρους του δικτύου και της διαδικασίας εκπαίδευσής του.\n",
    "4. Το **architecture.m** αποτελεί υποσυνάρτηση του **cnn_init.m**, καθώς ορίζει την αρχιτεκτονική του δικτύου και αρχικοποιεί τις παραμέτρους του κάθε επιπέδου (layer).\n",
    "\n",
    "Σκοπός του παρόντος μαθήματος είναι ο πειραματισμός με την αρχιτεκτονική ενός δικτύου και επομένως θα επέμβουμε μόνο στο τελευταίο αρχείο.\n",
    "\n",
    "Στο φάκελο **data/mnist-baseline** βρίσκεται η βάση δεδομένων (dataset) που θα χρησιμοποιήσουμε για την άσκηση."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST Dataset\n",
    "\n",
    "Περιλαμβάνει ένα σύνολο grayscale εικόνων από χειρόγραφα ψηφεία.\n",
    "\n",
    "<img src='https://raw.githubusercontent.com/IoannisKansizoglou/DeepLectures/master\\images\\MNIST-dataset.jpg' align='center' width='90%'>\n",
    "\n",
    "* image size:    [ $28\\times28\\times1$ ]\n",
    "* training data: 60,000\n",
    "* testing data:  10,000\n",
    "* classes:       10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Σχεδιασμός νέας αρχιτεκτονικής\n",
    "\n",
    "Ανοίγουμε το αρχείο **architecture.m**. \n",
    "\n",
    "``` matlab\n",
    "function layers = architecture()\n",
    "\n",
    "    f=1/100 ;\n",
    "    layers = {} ;\n",
    "\n",
    "end\n",
    "```\n",
    "\n",
    "Παρατηρούμε μία μεταβλητή **f**. Λόγω της ReLU είναι καλό να αρχικοποιούμε τις παραμέτρους του δικτύου με τυχαίες μικρές τιμές. Για το λόγο αυτό ορίζουμε την τιμή f=1/100 που πολλαπλασιάζεται με την randn και επιστρέφει τυχαίες μικρές ποσότητες. Επίσης έχει αρχικοποιηθεί μία κενή δομή (struct) με όνομα layers. \n",
    "\n",
    "Για να προσθέσουμε ένα νέο επίπεδο στο τέλος της δομής εργαζόμαστε ως εξής:\n",
    "\n",
    "``` matlab\n",
    "layers{end+1} = struct(...); \n",
    "```\n",
    "\n",
    "όπου μέσα στη δομή διευκρινίζονται το είδος του επιπέδου και οι παράμετροί του."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layers and Activation Functions in MatConvNet\n",
    "\n",
    "#### Convolutional layer\n",
    "\n",
    "struct(\n",
    "<span style='color:purple'>'type'</span>, <span style='color:purple'>'conv'</span>, <span style='color:purple'>'weights'</span>, {{f*randn($K_h$,$K_w$,Channels,Depth, <span style='color:purple'>'single'</span>), zeros(1, Depth, <span style='color:purple'>'single'</span>)}}, <span style='color:purple'>'stride'</span>, S, <span style='color:purple'>'pad'</span>, P);\n",
    "\n",
    "Θυμίζουμε ότι:\n",
    "\n",
    "<img src='https://raw.githubusercontent.com/IoannisKansizoglou/DeepLectures/master/images/Convolution3d.PNG' width=55% align='right'>\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "Width = \\frac{I_w-K_w+2P}{S}+1\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "Height = \\frac{I_h-K_h+2P}{S}+1\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "Channels = Depth\\_of\\_previous\\_layer\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "Depth = Number\\_of\\_filters\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://raw.githubusercontent.com/IoannisKansizoglou/DeepLectures/master/images/aloneReLU.png' width='50%' align='right'>\n",
    "\n",
    "#### ReLU activation function\n",
    "\n",
    "struct(<span style='color:purple'>'type'</span>, <span style='color:purple'>'relu'</span>);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MaxPool layer\n",
    "\n",
    "struct(\n",
    "<span style='color:purple'>'type'</span>, <span style='color:purple'>'pool'</span>, <span style='color:purple'>'method'</span>, <span style='color:purple'>'max'</span>, <span style='color:purple'>'pool'</span>, [$K_h$, $K_w$], <span style='color:purple'>'stride'</span>, S, <span style='color:purple'>'pad'</span>, P);\n",
    "\n",
    "Δεδομένου ότι $S=K_h=K_w$ και $P=0$, θυμίζουμε ότι:\n",
    "\n",
    "<img src='https://raw.githubusercontent.com/IoannisKansizoglou/DeepLectures/master/images/Maxpooling3d.PNG' width=55% align='right'>\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "Width = \\frac{I_w}{K_w}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "Height = \\frac{I_h}{K_h}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "Depth = Depth\\_of\\_previous\\_layer\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dense layer\n",
    "\n",
    "struct(\n",
    "<span style='color:purple'>'type'</span>, <span style='color:purple'>'conv'</span>, <span style='color:purple'>'weights'</span>, {{f*randn(1,1,Channels,Units, <span style='color:purple'>'single'</span>), zeros(1,Units, <span style='color:purple'>'single'</span>)}}, <span style='color:purple'>'stride'</span>, 1, <span style='color:purple'>'pad'</span>, 0);\n",
    "<p><br></p>\n",
    "<div class=\"row\">\n",
    "  <div class=\"column\">\n",
    "    <img src='https://raw.githubusercontent.com/IoannisKansizoglou/DeepLectures/master/images/DenseConv1.PNG' width=49% align='left'>\n",
    "  </div>\n",
    "  <div class=\"column\">\n",
    "    <img src='https://raw.githubusercontent.com/IoannisKansizoglou/DeepLectures/master/images/DenseConv2.PNG' width=49% align='right'>\n",
    "  </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://raw.githubusercontent.com/IoannisKansizoglou/DeepLectures/master/images/Softmax.PNG' width='50%' align='right'>\n",
    "\n",
    "#### Softmax\n",
    "\n",
    "<p><br></p>\n",
    "\n",
    "struct(<span style='color:purple'>'type'</span>, <span style='color:purple'>'softmaxloss'</span>);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training vs Validation Data\n",
    "\n",
    "<img src='https://raw.githubusercontent.com/IoannisKansizoglou/DeepLectures/master/images/Overfitting.png' width='40%' align='right'>\n",
    "\n",
    "Αν η εκπαίδευση ενός δικτύου διαρκέσει για πολλές επαναλήψεις (**epochs**), παρατηρείται **overfitting** στα δεδομένα εκπαίδευσης. Το γεγονός αυτό είναι ανεπιθύμητο καθώς οταν δοθούν στο δίκτυο νέα δεδομένα δεν μπορεί να τα ξεχωρίσει αποδοτικά. Για το λόγο αυτό κατά τη διάρκεια της εκπαίδευσης, συνήθως μετά από κάθε epoch, εισάγουμε στο σύστημα ορισμένα δεδομένα που δεν έχουν συμπεριληφθεί στην εκπαίδευση για να δούμε πως τα πηγαίνει σε αυτά. Τα δεδομένα αυτά ονομάζονται **validation data**. \n",
    "\n",
    "**ΠΡΟΣΟΧΗ**: Τα validation data τα εισάγουμε κάθε φορά απλά για να δούμε το σφάλμα του συστήματος **αλλά δεν διορθώνουμε τις παραμέτρους με βάσει αυτά**, παρα μόνο με τα δεδομένα εκπαίδευσης (training data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Εγκατάσταση\n",
    "\n",
    "* Αποσυμπιέζουμε το συμπιεσμένο αρχείο **matconvnet-1.0-beta23.tar**.\n",
    "* Αντιγράφουμε το φάκελο **matconvnet-1.0-beta23** στο σημείο που βρίσκονται τα εγκατεστημένα αρχεία του matlab.\n",
    "* Ανοίγουμε το matlab και πηγαίνουμε στο path μέσα στο φάκελο **matconvnet-1.0-beta23**.\n",
    "* Εκτελούμε τις παρακάτω εντολές\n",
    "\n",
    "Αν το Matlab ειναι εγκατεστημένο στα **Αρχεία Εφαρμογών**\n",
    "\n",
    "``` matlab\n",
    ">> mex -setup:'C:\\Program Files\\MATLAB\\R2016b\\bin\\win64\\mexopts\\msvc2015.xml' C\n",
    ">> mex -setup:'C:\\Program Files\\MATLAB\\R2016b\\bin\\win64\\mexopts\\msvcpp2015.xml' C++\n",
    ">> run matlab/vl_compilenn;\n",
    ">> run matlab/vl_setupnn.m\n",
    "```\n",
    "\n",
    "Αν το Matlab ειναι εγκατεστημένο στην **Επιφάνεια Εργασίας**\n",
    "\n",
    "``` matlab\n",
    ">> mex -setup:'C:\\Users\\**Username**\\Desktop\\MATLAB\\R2016b\\bin\\win64\\mexopts\\msvc2015.xml' C\n",
    ">> mex -setup:'C:\\Users\\**Username**\\Desktop\\MATLAB\\R2016b\\bin\\win64\\mexopts\\msvcpp2015.xml' C++\n",
    ">> run matlab/vl_compilenn;\n",
    ">> run matlab/vl_setupnn.m\n",
    "```\n",
    "\n",
    "Σε περίπτωση που είναι εγκατεστημένο σε άλλο μέρος πρέπει να βρείτε το path για να το συμπεριλάβετε στις δύο πρώτες εντολές.\n",
    "\n",
    "``` matlab\n",
    ">> mex -setup:'**PATH**\\MATLAB\\R2016b\\bin\\win64\\mexopts\\msvc2015.xml' C\n",
    ">> mex -setup:'**PATH**\\MATLAB\\R2016b\\bin\\win64\\mexopts\\msvcpp2015.xml' C++\n",
    ">> run matlab/vl_compilenn;\n",
    ">> run matlab/vl_setupnn.m\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Εφαρμογή - example\n",
    "\n",
    "**Να υλοποιηθεί το δίκτυο με την παρακάτω αρχιτεκτονική και να εκπαιδευτεί για 6 epochs.**\n",
    "\n",
    "<img src='https://raw.githubusercontent.com/IoannisKansizoglou/DeepLectures/master/images/Example.PNG' width='100%' align='center' >\n",
    "\n",
    "Πρώτα φορτώνουμε το **imdb.mat** και ας εμφανίσουμε ορισμένα στοιχεία του (π.χ. το 1ο)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load(C:\\...\\example\\data\\mnist-baseline\\imdb.mat)\n",
      "\n",
      "imshow(images.data(:,:,1))\n"
     ]
    }
   ],
   "source": [
    "# Load imdb.mat and imshow\n",
    "print('load(C:\\...\\example\\data\\mnist-baseline\\imdb.mat)')\n",
    "print('\\nimshow(images.data(:,:,1))')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Έπειτα σχεδιάζουμε την αρχιτεκτονική προσθέτοντας **structs** στο **architecture.m** .\n",
    "\n",
    "**ΠΡΟΣΟΧΗ**: Τα μεγέθη των φίλτρων πρέπει να υπολογιστούν βάσει των εξισώσεων που αναλύθηκαν παραπάνω.\n",
    "\n",
    "Αποθηκεύουμε το αρχείο και εκτελούμε την εντολή:\n",
    "\n",
    "\n",
    "``` matlab\n",
    ">> run_experiments\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Πιθανά λάθη\n",
    "\n",
    "<img src='https://raw.githubusercontent.com/IoannisKansizoglou/DeepLectures/master/images/FiltersError.PNG' align='right' width='50%'>\n",
    "\n",
    "Σφάλματα αρχιτεκτονικής δεν επιτρέπουν την εκκίνηση της εκπαίδευσης. Το σφάλμα εντοπίζεται στην **vl_nnconv** όπως φαίνεται δίπλα. Διαβάζουμε την πρώτη κόκκινη πρόταση. Μπορεί να οφείλεται σε:\n",
    "\n",
    "* Μη συμβατό αριθμό των καναλιών του φίλτρου με το βάθος του προηγούμενου επιπέδου\n",
    "* Λάθος διαστάσεις του φίλτρου\n",
    "* Μη συμβατό αριθμό φίλτρων με αριθμό biases του επιπέδου\n",
    "* κλπ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Αξιολογώντας την εκπαίδευση\n",
    "\n",
    "<img src='https://raw.githubusercontent.com/IoannisKansizoglou/DeepLectures/master/images/Losses.PNG' align='right' width='50%'>\n",
    "\n",
    "Παρατηρούμε κυρίως τις **καμπύλες του loss** (**objective** στην matconvnet).\n",
    "Με μπλε απεικονίζονται οι καμπύλες των training data και με πορτοκαλί αυτές των validation data.\n",
    "\n",
    "To **top1err** υπολογίζει το ποσοστό των λάθος προβλέψεων ελέγχοντας στην έξοδο μόνο την πρόβλεψη του νευρώνα με την μεγαλύτερη τιμή. Αντιθέτως, το **top2err** υπολογίζει το ποσοστό των λάθος προβλέψεων θεωρώντας, ωστόσο, ως σωστή μία πρόβλεψη εφόσον στην έξοδο ο νευρώνας που αντιστοιχεί στην σωστή κλάση ανήκει στους πέντε νευρώνες με την μέγιστη τιμή.\n",
    "\n",
    "Η απόδοση του δικτύου καθορίζεται από το **top1accuracy** των validation data, το οποίο υπολογίζεται ως:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "top1accuracy(\\%) = ( 1 - top1err ) * 100\\%\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Όσο αυξάνεται η απόσταση του training και του validation loss, τόσο ενισχύεται το φαινόμενο του overfitting, με αποτέλεσμα σταδιακά το validation accuracy να μην βελτιώνεται άλλο. Αυτό πρακτικά σημαίνει ότι το δίκτυο παύει να \"μαθαίνει\" από τα training data χρήσιμες πληροφορίες για την επίλυση του προβλήματος που επιθυμούμε. Σε αυτήν την περίπτωση λέμε ότι το δίκτυο πάυει να γενικέυει.\n",
    "\n",
    "Γενικότερα προσπαθούμε να σταματήσουμε την εκπαίδευση σε σημείο ούτως ώστε η απόσταση των δύο losses να μην έχει αυξηθεί υπερβολικά και το validation **top1accuracy** να είναι ικανοποιητικά υψηλό αναφορικά με το πρόβλημα που αντιμετωπίζουμε. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "1] http://www.vlfeat.org/matconvnet/\n",
    "\n",
    "2] https://medium.com/@kanchansarkar/relu-not-a-differentiable-function-why-used-in-gradient-based-optimization-7fef3a4cecec\n",
    "\n",
    "3] https://en.wikipedia.org/wiki/Overfitting"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "144px",
    "width": "259px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "296.11px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
